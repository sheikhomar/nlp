{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NLP, we can have intrinsic or extrinsic evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intrinsic evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP tasks like machine translation may consists of multiple subtasks. Instead of evaluating the entire pipeline (which may take a long time), we may want to evaluate parts of the system. In intrinsic evaluation, we want to measure the \"goodness\" of a subtask in itself. We take a specific intermediate subtask e.g. the task of converting words to word vectors and evaluate it on analogy completion or word pair correlation with human judgement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of evaluation is simple and fast. Sometimes, it can help us understand how the system works e.g., what hyperparamters actually have an impact on the metric of similarity. However, improvements on the intrinsic task do not necessary translate to improvements in the overall task like machine translation or name-entity recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vector Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One popular intrinsic word vector evaluation is the **word vector analogies**. Basically, we can solve simple analogy problems by using vector arithmetic. The expression for man-to-woman is like king-to-queen is given as:\n",
    "$$\n",
    "\\mathbf{x}_{queen} = \\mathbf{x}_{woman} - \\mathbf{x}_{man} + \\mathbf{x}_{king}\n",
    "$$\n",
    "\n",
    "Basically, we can evaluate word vectors by how well their cosine distance captures intuitive semantic and syntactic analogy questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/mikolov-gender-vectors.png\" width=\"200\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to identify the word vector $\\mathbf{x}_d$ that maximises the cosine similarity:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "d= \\arg \\max_{i} \\frac{ \\left( \\mathbf{x}_b - \\mathbf{x}_a + \\mathbf{x}_c \\right)^T \\mathbf{x}_i }{ \\lVert   \\mathbf{x}_b - \\mathbf{x}_a + \\mathbf{x}_c \\Vert }\n",
    "$$\n",
    "where\n",
    "- $\\mathbf{x}_a$ is the word vector for \"man\"\n",
    "- $\\mathbf{x}_b$ is the word vector for \"woman\"\n",
    "- $\\mathbf{x}_c$ is the word vector for \"king\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, we want the nearest word of \"woman\" - \"man\" + \"kind\" to be \"queen\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the following dataset of analogies to evaluate our word vectors: https://github.com/nicholas-leonard/word2vec/blob/master/questions-words.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/word-vector-eval-plots.png\" width=\"600\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another intrinsic evaluation is correlation evaluation. The cosine similarity between word vector pairs are compared to similarity assigned by humans. There are several datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordSimilarity-353 contains two sets of English word pairs along with human-assigned similarity judgements. The collection can be used to train and/or test computer algorithms implementing semantic similarity measures (i.e., algorithms that numerically estimate similarity of natural language words). Link: http://www.cs.technion.ac.il/~gabr/resources/data/wordsim353/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimLex-999 provides a way of measuring how well models capture similarity, rather than relatedness or association. The scores in SimLex-999 therefore differ from other well-known evaluation datasets such as WordSim-353 (Finkelstein et al. 2002). SimLex-999 is challenging for computational models to replicate because, in order to perform well, they must learn to capture similarity independently of relatedness/association. This is hard because most language-based representation-learning models infer connections between concepts from their co-occurrence in corpora, and co-occurrence primarity reflects relatedness not similarity. Link: https://fh295.github.io/simlex.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach is to visalise the embeddings and get a qualitative evaluation of the word vectors. We can use t-SNE to project the high dimensional word vectors to 2D or 3D and observe how words cluster. We have to be a bit careful when interpreting the results of t-SNE because the algorithm is stochastic and can produce different results on each run. Do not run the algorithm multiple times and pick the representation that match your own intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/word-vector-space-similar-words.png\" width=\"700\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrinsic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrinsic evaluation measures the \"goodness\" of the system on a real task.\n",
    "\n",
    "The problem is that the process of extrinsic evaluation can take a very long time because the chosen model can take some time to train. Therefore, trying out different word vectors or different hyperparameters may take a long time. For example, it may take long to compare word vectors based on the Pearson correlation for the co-occorrence matrix with the raw count of the words.\n",
    "\n",
    "We have to careful with extrinsic evaluation though. It is not advisable to tune multiple parts of the system and evaluate it once because if the overall task improves then we have no idea which part actually is responsible for the improvement. Therefore, when doing extrinsic evaluation it is better to change only one part of the system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
