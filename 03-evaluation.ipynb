{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NLP, we can have intrinsic or extrinsic evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intrinsic evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP tasks like machine translation may consists of multiple subtasks. Instead of evaluating the entire pipeline (which may take a long time), we may want to evaluate parts of the system. In intrinsic evaluation, we want to measure the \"goodness\" of a subtask in itself. We take a specific intermediate subtask e.g. the task of converting words to word vectors and evaluate it on analogy completion or word pair correlation with human judgement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of evaluation is simple and fast. Sometimes, it can help us understand how the system works e.g., what hyperparamters actually have an impact on the metric of similarity. However, improvements on the intrinsic task do not necessary translate to improvements in the overall task like machine translation or name-entity recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vector Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One popular intrinsic word vector evaluation is the **word vector analogies**. Basically, we can evaluate word vectors by how well their cosine distance after addition captures intuitive semantic and syntactic analogy questions. For example, man-to-woman is like king-to-queen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to identify the word vector $\\mathbf{x}_d$ that maximises the cosine similarity:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "d= \\arg \\max_{i} \\frac{ \\left( \\mathbf{x}_b - \\mathbf{x}_a + \\mathbf{c} \\right)^T \\mathbf{x}_i }{ \\lVert   \\mathbf{x}_b - \\mathbf{x}_a + \\mathbf{x}_c \\Vert }\n",
    "$$\n",
    "where\n",
    "- $\\mathbf{x}_a$ is the word vector for \"man\"\n",
    "- $\\mathbf{x}_b$ is the word vector for \"woman\"\n",
    "- $\\mathbf{x}_c$ is the word vector for \"king\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, we want the nearest word of \"woman\" - \"man\" + \"kind\" to be \"queen\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the following dataset of analogies to evaluate our word vectors: https://github.com/nicholas-leonard/word2vec/blob/master/questions-words.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/word-vector-eval-plots.png\" width=\"600\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another intrinsic evaluation is correlation evaluation. The cosine similarity between word vector pairs are compared to similarity assigned by people. \n",
    "\n",
    "For example, the WordSimilarity-353 Test Collection contains two sets of English word pairs along with human-assigned similarity judgements. The collection can be used to train and/or test computer algorithms implementing semantic similarity measures (i.e., algorithms that numerically estimate similarity of natural language words). Link: http://www.cs.technion.ac.il/~gabr/resources/data/wordsim353/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrinsic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrinsic evaluation measures the \"goodness\" of the system on a real task.\n",
    "\n",
    "The problem is that the process of extrinsic evaluation can take a very long time because the chosen model can take some time to train. Therefore, trying out different word vectors or different hyperparameters may take a long time. For example, it may take long to compare word vectors based on the Pearson correlation for the co-occorrence matrix with the raw count of the words.\n",
    "\n",
    "We have to careful with extrinsic evaluation though. It is not advisable to tune multiple parts of the system and evaluate it once because if the overall task improves then we have no idea which part actually is responsible for the improvement. Therefore, when doing extrinsic evaluation it is better to change only one part of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
